{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c1aa5dfe864d09af725377a13d9c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1580945031101_0002</td><td>pyspark</td><td>idle</td><td></td><td></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType, ArrayType, IntegerType\n",
    "from pyspark.sql.functions import udf, col, regexp_replace, count\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.classification import NaiveBayes, RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean Yelp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "\n",
    "bucketpath = 's3://aust-galv-aust-cap2/YelpData/'\n",
    "bus_s3 = bucketpath + 'business.json'\n",
    "cleaned_rev_s3 = bucketpath + 'review_cleaned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c890b3ce174cefbaaa5d95f4c662ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rev_df = spark.read.json(rev_s3)\n",
    "business_df = spark.read.json(bus_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348494ad15c247d185d029f2d3b9a6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_udf = udf(lambda rating: 1 if rating >= 4.0 else 0, IntegerType())\n",
    "\n",
    "def clean_data_and_upload(s3_path, filename):\n",
    "    # Download review dataset from s3 bucket, clean data, and save new dataframe\n",
    "    # to s3 bucket\n",
    "    reviews_df = spark.read.json(s3_path + filename)\n",
    "    cleaned_review_df = rev_df.select(regexp_replace('text', r'[^\\w\\s]', '').alias('clean_text'),\n",
    "                                      'stars', sentiment_udf('stars').alias('sentiment'))\n",
    "    \n",
    "    cleaned_review_df.write.format('json').save(s3_path + \"review_cleaned/\")\n",
    "    reviews_df.unpersist()   # Remove old dataframe from memory\n",
    "    \n",
    "    return cleaned_review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6bbe5aad644512bf298f809380d832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_df = clean_data_and_upload(bucketpath, \"review.json\")\n",
    "review_df = review_df.repartition(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c887fa61a54cfda406b3c5ea5c4b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-----+\n",
      "|          clean_text|sentiment|stars|\n",
      "+--------------------+---------+-----+\n",
      "|Sugar Factory is ...| negative|  3.0|\n",
      "|The food is still...| negative|  1.0|\n",
      "|This review is fo...| positive|  5.0|\n",
      "|A disclaimer Im a...| negative|  3.0|\n",
      "|Wow  Keep in mind...| negative|  2.0|\n",
      "+--------------------+---------+-----+"
     ]
    }
   ],
   "source": [
    "review_df.createOrReplaceTempView(\"review\")\n",
    "\n",
    "result = spark.sql(\"\"\"SELECT *\n",
    "                      FROM review\n",
    "                      LIMIT 5\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore business dataset\n",
    "Note: most EDA has been removed for the sake of brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df.createOrReplaceTempView(\"business\")\n",
    "spark.sql(\"\"\"SELECT *\n",
    "             FROM business\n",
    "             LIMIT 5\"\"\").show()\n",
    "# result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = spark.sql(\"\"\"SELECT city, COUNT(*) as count\n",
    "                        FROM business\n",
    "                        GROUP BY city\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c177aa7f6444b77a9da19e79f9b96bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6685900\n",
      "[Row(clean_text='Sugar Factory is an ok experience The food lacked flavor The service started out great but gets noticeably bad the last 75 of your time there The music is really loud The tables are small while the plates are huge my friend had to put her plate in her lap because there was no where else on the dinky table The prices for the Goblets are high so look for check in deals on Yelp and other voucher websites or skip them altogether Id go back with the realization that their Happy Hour sucks \\n\\nWe went after reading about the happy hour and what a ripoff Id have been more pleased if the Goblets were 50 off end of story Inside the server said buy one Goblet and get select apps for 3 I figured it was a great deal and thought you could choose 2 or 3 apps for 3 each I mean the Goblet is the price of an entree at dinner for goodness sake Well you could only choose ONE app at that price PER Goblet I chose the burger thinking I was getting a great deal Not so much The burger came out and it was honest to goodness the size of a slider It was not as others have posted pictures of who went earlier when the restaurant first opened They honestly thought I was going to pay 3 for that little thing The server while nice and all smiles failed to mention that Im not a greedy person but these servers should learn how to describe what they are selling their patrons \\n\\nI sent the slider back and ordered a burger The table next to us suffered the same fate and they sent their little slider back too and asked for a traditional sized sandwich which is 13 That burger didnt arrive for 20 minutes Three people walked by and kept saying itll be right out I wasnt in a hurry but at a certain point you start to notice The burger arrived and it was cooked medium noticeably pink in the middle so Im not sure what took so long to cook it lt looked great and juicy but it lacked ANY and ALL seasoning It was bland as shit and there was no salt in sight Even with the crispy onions strings they didnt help\\n\\nThe Goblet was great but youd get sticker shock if they listed the price of them on the menu in fact they dont list the price for ANY of their drinks I despise sneaky restaurants that do that You have to ask the server and it becomes a talking point when it shouldnt be 39 for a drink is not chump change for any time of the day On top of that they ran out of all citrus fruits at the bar no lemons for the water no limes for the vodka soda and no lemons for my 39 Iced Tea Vodka drink The server had the audacity to bring over 1 One sad lemon slice from the end of a lemon with all the white pith on a big plate It wasnt enough juice in that thing to squeeze a drop in a thimble During dinner a server walks in from the back with bags of citrus fruits from the local grocery store Who is running this operation Get it together\\n\\nTowards the end of the meal as usual the server disappears and we have to ask random people and managers to bring us our checkThis has become an annoying part of dining out lately Youll get great service at the start and then it tapers off dramatically to no service at all then they hoover over you to leave a 20 tip but were absent the last 75 of the meal Oddly they dont even have check presenters here Everything is ordered and check is presented on a ipad style device Its quick but we never were presented with a itemized bill when they swiped our credit card or after the charge was processed Its best to ask for a bill BEFORE paying and keep a tally of the charges', sentiment='negative', stars=3.0)]"
     ]
    }
   ],
   "source": [
    "print(review_df.count())\n",
    "review_df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb48955922e44848bf89f929bbf189cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|n_words|count|\n",
      "+-------+-----+\n",
      "|      1|  628|\n",
      "|      6| 2031|\n",
      "|      3|  477|\n",
      "|      5| 1115|\n",
      "|      9| 5257|\n",
      "|      4|  770|\n",
      "|      8| 3944|\n",
      "|      7| 2829|\n",
      "|      2|  499|\n",
      "|      0|  546|\n",
      "+-------+-----+"
     ]
    }
   ],
   "source": [
    "wordcount_df.groupBy('n_words') \\\n",
    "  .agg(count('n_words').alias('count')) \\\n",
    "  .filter(col('n_words')<10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27814d672b94fec9b9a03739b3dbc1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We restrict the data to reviews with more than 5 words. This removes just 4,000 out of 7 million reviews\n",
    "\n",
    "wordcount_udf = udf(lambda string: len(string.split()), IntegerType())\n",
    "\n",
    "review_data = review_df.select('clean_text','stars', 'sentiment').filter(wordcount_udf('clean_text')>5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e7f73e85564bf4b45da0d149331ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizes data by word\n",
    "tokenizer = Tokenizer(inputCol=\"clean_text\", outputCol=\"words\")\n",
    "tokenized_data = tokenizer.transform(review_data)\n",
    "\n",
    "# Removes stop words\n",
    "stopwords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"stopped_words\", stopWords=stopwords)\n",
    "stopremoved_data = remover.transform(tokenized_data).select(\"clean_text\", \"sentiment\", \"stopped_words\")\n",
    "\n",
    "# Stem words\n",
    "stemmer = SnowballStemmer(language=\"english\")\n",
    "stemmer_udf = udf(lambda tokens: [stemmer.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "stemmed_data = stopremoved_data.select(\"clean_text\", \"sentiment\", stemmer_udf(\"stopped_words\").alias(\"stemmed_words\"))\n",
    "\n",
    "# Gets tfidf for all words. HashingTF is a Transformer which takes sets of terms and converts \n",
    "# those sets into fixed-length feature vectors.\n",
    "hashing_TF = HashingTF(inputCol=\"stemmed_words\", outputCol=\"raw_features\")\n",
    "tf_data = hashing_TF.transform(stemmed_data).select(\"clean_text\", \"sentiment\", \"raw_features\")\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\", minDocFreq=50)\n",
    "idf_model = idf.fit(tf_data)\n",
    "tfidf_data = idf_model.transform(tf_data).select(\"clean_text\", \"sentiment\", \"features\")\n",
    "\n",
    "train, test = tfidf_data.randomSplit([.8, .2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeff469f6ab947c6aaf675a9e6b61707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(clean_text='The sandwiches are great Like some of the other reviews the sides and also the cookies are better left alone I always have a hard time picking something off the menu cause its so big I dont have a favorite yet but I have ordered the Shea stadium the most \\nThe sandwich makers are OK some what friendly but for the most part dont talk very much \\nThe other day we went in for some food and the TV was blaring a sports game so loud we really had a hard time hearing each other \\nGood thing the man behind the counter noticed this after a little bit and turned it down with out anyone asking to do so \\nThe bathrooms are OK and the seating isnt the best \\nI think Im going to have to try all the subs before I find my favorite or just have like 6 or 7 favorites', sentiment=0, features=SparseVector(262144, {1353: 1.6814, 2325: 2.6672, 2437: 6.2655, 8804: 3.2286, 11137: 5.1736, 13957: 2.1708, 18659: 3.703, 20376: 4.8544, 21294: 4.2003, 24918: 3.9971, 25615: 2.7694, 30006: 2.8128, 35800: 2.6803, 41660: 4.2039, 70028: 2.409, 72125: 3.3461, 76764: 2.1557, 77099: 4.2183, 87273: 3.7498, 87758: 6.4778, 88302: 3.5454, 91878: 2.5437, 101402: 2.0077, 104220: 3.2448, 107499: 2.2269, 109810: 2.1866, 111370: 4.1579, 113432: 1.097, 115917: 2.307, 116342: 4.0302, 121133: 1.0938, 121517: 2.3976, 122516: 6.3763, 126770: 4.7816, 128331: 4.6095, 134024: 3.947, 138356: 1.1512, 138895: 3.9132, 141854: 2.6504, 146139: 2.0921, 147136: 1.7607, 151571: 2.37, 152715: 1.6291, 156404: 3.5013, 158870: 1.5701, 165416: 3.6952, 166027: 1.9095, 167131: 3.4061, 167290: 6.3288, 168436: 3.598, 170414: 2.9625, 170441: 7.8386, 172477: 1.2718, 183117: 2.1692, 198790: 1.573, 201223: 7.534, 202353: 4.6468, 208258: 2.6369, 220184: 2.5252, 232051: 4.4279, 238870: 2.0916, 249180: 2.378, 252567: 8.4912, 260503: 6.7424}))]"
     ]
    }
   ],
   "source": [
    "tfidf_data.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making an NLP Pipeline\n",
    "Note: Spark has no built-in Stemmer so the pipeline doesn't include this preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38652d5049e94b0796f9ab06a2c9797b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stopwords = StopWordsRemover.loadDefaultStopWords('english')\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"clean_text\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"stopped_words\", stopWords=stopwords)\n",
    "hashing_TF = HashingTF(inputCol=remover.getOutputCol(), outputCol=\"raw_features\")\n",
    "idf = IDF(inputCol=hashing_TF.getOutputCol(), outputCol=\"features\", minDocFreq=2)\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashing_TF, idf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and splitting the data\n",
    "Note: under normal circumstances I would use cross validation on the model, but due to time constraints a standard train/test split was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626343b9d4ea4cc7ae57d745de0dd2d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the pipeline to training documents.\n",
    "processed_model = pipeline.fit(review_data)\n",
    "processed_data = processed_model.transform(review_data)\n",
    "\n",
    "train, test = processed_data.randomSplit([.8, .2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f060103420405eb53ade172654e652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "truepos_udf = udf(lambda ytrue, ypred: 1 if (ytrue == 1. and ypred == 1.) else 0, IntegerType())\n",
    "falsepos_udf = udf(lambda ytrue, ypred: 1 if (ytrue == 0. and ypred == 1.) else 0, IntegerType())\n",
    "falseneg_udf = udf(lambda ytrue, ypred: 1 if (ytrue == 1. and ypred == 0.) else 0, IntegerType())\n",
    "trueneg_udf = udf(lambda ytrue, ypred: 1 if (ytrue == 0. and ypred == 0.) else 0, IntegerType())\n",
    "\n",
    "\n",
    "def get_model_scores(df):\n",
    "    # Gets the confusion matrix from the model, then calculates various scores \n",
    "    # of the test data in the model\n",
    "    confusion_matrix = nb_result.select(truepos_udf(\"sentiment\", \"prediction\").alias(\"tp\"),\n",
    "                                        falsepos_udf(\"sentiment\", \"prediction\").alias(\"fp\"),\n",
    "                                        falseneg_udf(\"sentiment\", \"prediction\").alias(\"fn\"),\n",
    "                                        trueneg_udf(\"sentiment\", \"prediction\").alias(\"tn\")) \\\n",
    "                                .groupBy().sum().collect()\n",
    "\n",
    "    tp, fp, fn, tn = confusion_matrix[0]\n",
    "    total = tp + fp + fn + tn\n",
    "    accuracy = (tp + tn)/(tp + fp + fn + tn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    print(f'Test sample size: {total}')\n",
    "    print(f'Accuracy:  {accuracy:1.2%}')\n",
    "    print(f'Precision: {precision:1.2%}')\n",
    "    print(f'Recall:    {recall:1.2%}')\n",
    "    \n",
    "    return accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training NaiveBayes and RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b3f0a610014893932092e0e94b6274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f895d30ebe2c44c582fdabdbd25adcc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb = NaiveBayes(featuresCol='features', labelCol='sentiment', smoothing=1.0, modelType='multinomial')\n",
    "nb_model = nb.fit(train)\n",
    "nb_result = nb_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = get_model_scores(nb_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4466155166047c7833a7c429bacc42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(stars=5.0, sentiment=1, prediction=1.0), Row(stars=3.0, sentiment=0, prediction=0.0), Row(stars=1.0, sentiment=0, prediction=0.0), Row(stars=1.0, sentiment=0, prediction=0.0), Row(stars=5.0, sentiment=1, prediction=1.0), Row(stars=1.0, sentiment=0, prediction=0.0), Row(stars=3.0, sentiment=0, prediction=0.0), Row(stars=5.0, sentiment=1, prediction=0.0), Row(stars=5.0, sentiment=1, prediction=1.0), Row(stars=4.0, sentiment=1, prediction=1.0), Row(stars=5.0, sentiment=1, prediction=1.0), Row(stars=1.0, sentiment=0, prediction=0.0), Row(stars=1.0, sentiment=0, prediction=0.0), Row(stars=1.0, sentiment=0, prediction=0.0), Row(stars=1.0, sentiment=0, prediction=0.0)]"
     ]
    }
   ],
   "source": [
    "nb_result.select('stars', 'sentiment', 'prediction').take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b08a34e2ae40c2a2b03abd7798e3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d609f97d94a452595b7eef2126ca313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(featuresCol='features', labelCol='sentiment', numTrees=2, featureSubsetStrategy='sqrt')\n",
    "rfc_model = rfc.fit(train)\n",
    "rfc_result = rfc_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = get_model_scores(rfc_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "NaiveBayes result: \n",
    "* Accuracy: 84.8%\n",
    "* Precision: 88.4%\n",
    "* Recall: 88.5%\n",
    "* Relatively short train time\n",
    "\n",
    "RandomForest result: \n",
    "* Accuracy: 87.7%\n",
    "* Precision: 87.7%\n",
    "* Recall: 94.6%\n",
    "* Much longer train time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
